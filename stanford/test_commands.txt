- Basic test
	java -cp "*" -Xmx2g edu.stanford.nlp.pipeline.StanfordCoreNLP -annotators tokenize,ssplit,pos,lemma,ner,parse,dcoref -file input.txt

- http://nlp.stanford.edu/software/regexner.html
	java -mx1g -cp '*' edu.stanford.nlp.pipeline.StanfordCoreNLP -annotators 'tokenize,ssplit,pos,lemma,ner' -file JuliaGillard.txt # DOESN'T WORK
		- should be:
			java -cp "*" -mx1g edu.stanford.nlp.pipeline.StanfordCoreNLP -annotators tokenize,ssplit,pos,lemma,ner -file JuliaGillard.txt
	java -cp "*" -Xmx2g edu.stanford.nlp.pipeline.StanfordCoreNLP -annotators tokenize,ssplit,pos,lemma,ner,parse,dcoref -file JuliaGillard.txt
	java -cp "*" -Xmx2g edu.stanford.nlp.pipeline.StanfordCoreNLP -annotators tokenize,ssplit,pos,lemma,ner,regexner -file JuliaGillard_regexner.txt -regexner.mapping JuliaGillard_regexnerMappings.txt
	
- State Agency test
	java -cp "*" -Xmx2g edu.stanford.nlp.pipeline.StanfordCoreNLP -annotators tokenize,ssplit, pos,lemma,ner,regexner -file ../tests/NCStateAgencies_regexner.txt -regexner.mapping ../tests/NCStateAgencies_regexnerMappings.txt # add "parse" to annotator list to get parse tree and dependencies.
	java -cp "*" -Xmx2g edu.stanford.nlp.pipeline.StanfordCoreNLP -annotators tokenize,ssplit,pos,lemma,regexner -file ../tests/NCStateAgencies_regexner.txt -regexner.mapping ../tests/NCStateAgencies_regexnerMappings.txt
	
- Just NER
	java -mx600m -cp "*;lib\*" edu.stanford.nlp.ie.crf.CRFClassifier -loadClassifier classifiers/english.all.3class.distsim.crf.ser.gz -textFile ../tests/NCStateAgencies_regexner.txt > foo.txt
	java -mx600m -cp "*;lib\*" edu.stanford.nlp.ie.crf.CRFClassifier -loadClassifier classifiers/english.all.3class.distsim.crf.ser.gz -textFile ../tests/NCStateAgencies_regexner.txt -outputFormat inlineXML

- If I don't list annotators, I get an out of memory error.

		java -cp "*" -Xmx2g edu.stanford.nlp.pipeline.StanfordCoreNLP -file ../tests/NCStateAgencies_regexner.txt -regexner.mapping ../tests/NCStateAgencies_regexnerMappings.txt
		
- Use TokensRegex per http://stackoverflow.com/questions/40441963/how-to-use-a-custom-tokensregex-rules-annotator-with-stanford-corenlp-server
	java -cp "*" -Xmx2g edu.stanford.nlp.pipeline.StanfordCoreNLP -props custom.properties -file ./tokensregex/color.input.txt
	java -cp "*" -Xmx2g edu.stanford.nlp.pipeline.StanfordCoreNLP -props ../tests/Nitin.properties -file ../tests/Nitin.txt
	
- Server (see: http://stanfordnlp.github.io/CoreNLP/corenlp-server.html#getting-started)

	java -mx2g -cp "*" edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 #basic startup.
	
	>>> from pycorenlp import StanfordCoreNLP
	>>> nlp = StanfordCoreNLP("http://localhost:9000")
	>>> text = "nitaro74@gmail.com"
	>>> output = nlp.annotate(text, properties={"annotators":"tokenize, ssplit, pos, ner, regexner", "outputFormat":"json", "regexner.mapping":"mappings.txt"})
	>>> print(output)
	{'sentences': [{'index': 0, 'tokens': [{'index': 1, 'word': 'nitaro74@gmail.com', 'originalText': 'nitaro74@gmail.com', 'lemma': 'nitaro74@gmail.com', 'characterOffsetBegin': 0, 'characterOffsetEnd': 18, 'pos': 'NN', 'ner': 'PII.email_address', 'before': '', 'after': ''}]}]}